{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7Ki5mF9mqnICfcH97aSfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gulco/GlobalAIHubMachineLearningCourse/blob/main/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meYg9G9Db9Xd"
      },
      "source": [
        "#1) ML is focused on making predictions rather than analyzing existing data. \n",
        "#ML is interested in what will happen. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUTT-6PscJHs"
      },
      "source": [
        "#2) In supervised learning we work on a set of labeled data for train an algorithm. \n",
        "#(Random forest classification, linear regression, support vector machines)\n",
        "#In unsupervised learning we study clusters, distribution etc of unlabeled data. \n",
        "#(Clustering, anomaly detection, association)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcfR7m8KcJXP"
      },
      "source": [
        "#3) Test set is the sample of data used to provide an unbiased evaluation of \n",
        "#a final model fit on the training dataset while validation set refers to the \n",
        "#sample of data held back from training the model. The validation set also play \n",
        "#a role in model selection and preparation, such as feature selection and tuning \n",
        "#hyperparameters while test set is predominately used to describe the evaluation \n",
        "#of a final tuned model and provide an unbiased evaluation of a final model fit \n",
        "#on the training dataset."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d3yk15rcJhQ"
      },
      "source": [
        "#4) We need to prepare our data in order to transform raw data which is often \n",
        "#incomplete and inconsistent into an understandable format with certain \n",
        "#behaviors or trends. Main preprocessing steps are;\n",
        "#a) Importing libraries and data: Numpy for mathematical operation in the code, \n",
        "#pandas for importing and managing dataset, matplotlib for plot any type of \n",
        "#charts. In importing dataset process we identify and extract dependant and \n",
        "#independant variables.\n",
        "#b) Missing value handling: Identify and correctly handle the missing values \n",
        "#via deleting (less preferred, cause loss of data) or calculating the mean / \n",
        "#median values accordingly to the distribution of the dataset.\n",
        "#c) Checking the data types: ML modelling is based on mathematical equations. \n",
        "#Thus, we have to identify categorical data and encode it into numerical or \n",
        "#dummy values.\n",
        "#d) Train and test splitting: Split dataset into two separate sets so ML model \n",
        "#can learn from data to make predictions. Splitting can be varies according to \n",
        "#the dataset shape and size but generally the ratio is 70:30 (70% data for \n",
        "#train and 30% data for test) or 80:20 (80% data for train and 20% data for test).\n",
        "#e) Feature scaling: Feature scaling is a method to standardize the independent \n",
        "#variables of a dataset within a specific range so we can compare them on common \n",
        "#grounds."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClFm0FMDcJrS"
      },
      "source": [
        "#5) A discrete variable is a numeric variable that have a countable number of \n",
        "#values between any two values. A continuous variable is a numeric variable \n",
        "#that have an infinite number of values between any two values."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwiob6FcUjc"
      },
      "source": [
        "#6) The plot is a histogram for a discrete variable type. \n",
        "#Distribution is binomial thus in preprocess step we can check if we could split\n",
        "#the data into subgroups."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}